{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*",O

  "MockLlmApi": {

    // ========================================
    // LEGACY SINGLE BACKEND CONFIGURATION
    // ========================================
    // These settings are maintained for backward compatibility.
    // If you configure "Backends" below, these are ignored.
    // Otherwise, they automatically create a default Ollama backend.

    "BaseUrl": "http://localhost:11434/v1/",
    "ModelName": "llama3",


    // ========================================
    // MULTIPLE LLM BACKENDS (v1.8.0+)
    // ========================================
    // Configure multiple LLM providers for load balancing, failover, and flexibility.
    // Per-request selection via: X-LLM-Backend header or ?backend= query param
    // See: docs/MULTIPLE_LLM_BACKENDS.md

    "Backends": [

      // --- OLLAMA BACKENDS (Local LLM Server) ---
      {
        "Name": "ollama-llama3",
        "Provider": "ollama",
        "BaseUrl": "http://localhost:11434/v1/",
        "ModelName": "llama3",
        "ApiKey": null,                    // Optional: Add API key if your Ollama requires auth
        "MaxTokens": 8192,                 // Model-specific token limit
        "Enabled": true,
        "Weight": 3,                       // Higher weight = more requests in load balancing
        "MaxConcurrentRequests": 0,        // 0 = unlimited
        "HealthCheckPath": null,           // Future: "/health" for monitoring
        "Priority": 10                     // Higher = preferred backend
      },
      {
        "Name": "ollama-mistral",
        "Provider": "ollama",
        "BaseUrl": "http://localhost:11434/v1/",
        "ModelName": "mistral",
        "ApiKey": null,
        "MaxTokens": 8192,
        "Enabled": true,
        "Weight": 2,
        "MaxConcurrentRequests": 0,
        "HealthCheckPath": null,
        "Priority": 5
      },
      {
        "Name": "ollama-codellama",
        "Provider": "ollama",
        "BaseUrl": "http://localhost:11434/v1/",
        "ModelName": "codellama",
        "ApiKey": null,
        "MaxTokens": 16384,
        "Enabled": false,                  // Disabled by default
        "Weight": 1,
        "MaxConcurrentRequests": 0,
        "HealthCheckPath": null,
        "Priority": 3
      },
      {
        "Name": "ollama-mistral-nemo",
        "Provider": "ollama",
        "BaseUrl": "http://localhost:11434/v1/",
        "ModelName": "mistral-nemo",
        "ApiKey": null,
        "MaxTokens": 128000,               // 128k context window!
        "Enabled": false,                  // Enable this to test huge contexts
        "Weight": 2,
        "MaxConcurrentRequests": 0,
        "HealthCheckPath": null,
        "Priority": 6,
        "Description": "Mistral-Nemo 12B with 128k context - ideal for massive result sets and complex nested data"
      },

      // --- OPENAI BACKENDS (Cloud API) ---
      {
        "Name": "openai-gpt4-turbo",
        "Provider": "openai",
        "BaseUrl": "https://api.openai.com/v1/",
        "ModelName": "gpt-4-turbo",
        "ApiKey": "sk-proj-YOUR-API-KEY-HERE",  // REQUIRED for OpenAI
        "MaxTokens": 32768,
        "Enabled": false,                  // Disabled to avoid unexpected charges
        "Weight": 1,
        "MaxConcurrentRequests": 5,        // Rate limiting
        "HealthCheckPath": null,
        "Priority": 8
      },
      {
        "Name": "openai-gpt4",
        "Provider": "openai",
        "BaseUrl": "https://api.openai.com/v1/",
        "ModelName": "gpt-4",
        "ApiKey": "sk-proj-YOUR-API-KEY-HERE",
        "MaxTokens": 8192,
        "Enabled": false,
        "Weight": 1,
        "MaxConcurrentRequests": 5,
        "HealthCheckPath": null,
        "Priority": 7
      },
      {
        "Name": "openai-gpt35-turbo",
        "Provider": "openai",
        "BaseUrl": "https://api.openai.com/v1/",
        "ModelName": "gpt-3.5-turbo",
        "ApiKey": "sk-proj-YOUR-API-KEY-HERE",
        "MaxTokens": 4096,
        "Enabled": false,
        "Weight": 2,
        "MaxConcurrentRequests": 10,
        "HealthCheckPath": null,
        "Priority": 5
      },

      // --- LM STUDIO BACKENDS (Local Server) ---
      {
        "Name": "lmstudio-default",
        "Provider": "lmstudio",
        "BaseUrl": "http://localhost:1234/v1/",
        "ModelName": "local-model",        // Model name from LM Studio
        "ApiKey": null,                    // Usually not required
        "MaxTokens": 8192,
        "Enabled": false,
        "Weight": 1,
        "MaxConcurrentRequests": 0,
        "HealthCheckPath": null,
        "Priority": 4
      },
      {
        "Name": "lmstudio-experimental",
        "Provider": "lmstudio",
        "BaseUrl": "http://localhost:1234/v1/",
        "ModelName": "experimental-model",
        "ApiKey": null,
        "MaxTokens": 4096,
        "Enabled": false,
        "Weight": 1,
        "MaxConcurrentRequests": 0,
        "HealthCheckPath": null,
        "Priority": 1
      },

      // --- REMOTE OLLAMA INSTANCES ---
      {
        "Name": "ollama-remote-server",
        "Provider": "ollama",
        "BaseUrl": "http://192.168.1.100:11434/v1/",  // Remote server IP
        "ModelName": "llama3",
        "ApiKey": null,
        "MaxTokens": 8192,
        "Enabled": false,
        "Weight": 1,
        "MaxConcurrentRequests": 0,
        "HealthCheckPath": null,
        "Priority": 2
      }
    ],


    // ========================================
    // LLM GENERATION SETTINGS
    // ========================================

    "Temperature": 1.2,                   // 0.0 = deterministic, 2.0 = very creative/random
    "MaxInputTokens": 4096,               // Maximum input context size
    "MaxOutputTokens": 2048,              // Maximum output tokens (used for chunking)
    "TimeoutSeconds": 30,                 // HTTP timeout for LLM requests


    // ========================================
    // SSE STREAMING MODES (v1.8.0+)
    // ========================================
    // Configure Server-Sent Events streaming behavior.
    // See: docs/SSE_STREAMING_MODES.md

    "SseMode": "LlmTokens",               // LlmTokens | CompleteObjects | ArrayItems
    //   - LlmTokens: Token-by-token streaming (AI chat interfaces)
    //   - CompleteObjects: Complete objects per event (Twitter API, stock tickers)
    //   - ArrayItems: Array items with metadata (paginated results, bulk exports)
    // Override per-request: ?sseMode=CompleteObjects


    // ========================================
    // AUTOMATIC REQUEST CHUNKING (v1.8.0+)
    // ========================================
    // Automatically splits large requests into chunks to fit within token limits.
    // See: CHUNKING_AND_CACHING.md

    "EnableAutoChunking": true,           // Enable automatic chunking
    "MaxItems": 1000,                     // Max items per response AND cache size


    // ========================================
    // CACHING CONFIGURATION (v1.8.0+)
    // ========================================
    // Cache LLM responses to reduce latency and API costs.
    // See: CHUNKING_AND_CACHING.md

    "MaxCachePerKey": 5,                  // Cached variants per unique request
    "CacheSlidingExpirationMinutes": 15,  // Expire after inactivity
    "CacheAbsoluteExpirationMinutes": 60, // Maximum cache lifetime
    "CacheRefreshThresholdPercent": 50,   // Future: pre-fetch threshold
    "CachePriority": 1,                   // 0=Low, 1=Normal, 2=High, 3=NeverRemove
    "EnableCacheStatistics": false,       // Track cache hits/misses
    "EnableCacheCompression": false,      // Compress cached responses


    // ========================================
    // RESILIENCE POLICIES (Polly v8)
    // ========================================
    // Automatic retry and circuit breaker patterns for reliability.

    "EnableRetryPolicy": true,
    "MaxRetryAttempts": 3,                // Retry up to 3 times
    "RetryBaseDelaySeconds": 1.0,         // Exponential backoff: 1s, 2s, 4s

    "EnableCircuitBreaker": true,
    "CircuitBreakerFailureThreshold": 5,  // Open circuit after 5 failures
    "CircuitBreakerDurationSeconds": 30,  // Stay open for 30 seconds


    // ========================================
    // CUSTOM PROMPT TEMPLATES
    // ========================================
    // Override default prompts with custom templates.
    // Placeholders: {method}, {path}, {body}, {randomSeed}, {timestamp}

    "CustomPromptTemplate": null,         // null = use default
    "CustomStreamingPromptTemplate": null,


    // ========================================
    // DELAY SIMULATION
    // ========================================
    // Add realistic delays to simulate network latency.

    // Random delay before responding to any request
    "RandomRequestDelayMinMs": 0,
    "RandomRequestDelayMaxMs": 0,         // Random between Min and Max

    // Delay between streaming chunks (SSE)
    "StreamingChunkDelayMinMs": 0,
    "StreamingChunkDelayMaxMs": 0,


    // ========================================
    // RESPONSE OPTIONS
    // ========================================

    "IncludeShapeInResponse": false,      // Include JSON schema in response
    "EnableVerboseLogging": false,        // Detailed logging output


    // ========================================
    // GRAPHQL CONFIGURATION
    // ========================================
    // Settings for /graphql endpoint.

    "GraphQLMaxTokens": 500,              // 200-300 for small models, 500-1000 for large


    // ========================================
    // SIGNALR REAL-TIME DATA
    // ========================================
    // Configure SignalR hubs for real-time streaming data.

    "SignalRPushIntervalMs": 5000,        // Push interval (5 seconds)
    "HubContexts": [
      {
        "Name": "weather",
        "Description": "Realistic weather data with temperature, conditions, humidity, and wind speed",
        "Method": "GET",
        "Path": "/data/weather",
        "Body": null,
        "Shape": "{\"temperature\":25,\"condition\":\"sunny\",\"humidity\":60,\"windSpeed\":10}",
        "IsJsonSchema": false,
        "ApiContextName": "weather-station-1",
        "BackendName": null,               // null = use default backend selection
        "BackendNames": null,
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null                // null = normal data generation
      },
      {
        "Name": "stock-prices",
        "Description": "Real-time stock prices with ticker, price, change, and volume",
        "Method": "GET",
        "Path": "/data/stocks",
        "Body": null,
        "Shape": "{\"ticker\":\"AAPL\",\"price\":150.25,\"change\":2.5,\"volume\":1000000}",
        "IsJsonSchema": false,
        "ApiContextName": "market-data",
        "BackendName": "ollama-llama3",    // Fast local model for high-frequency simple data
        "BackendNames": null,
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null
      },
      {
        "Name": "vehicle-tracking",
        "Description": "GPS tracking data for vehicles with location, speed, and status",
        "Method": "GET",
        "Path": "/data/vehicles",
        "Body": null,
        "Shape": "{\"vehicleId\":\"V001\",\"lat\":40.7128,\"lng\":-74.0060,\"speed\":45,\"status\":\"moving\"}",
        "IsJsonSchema": false,
        "ApiContextName": "fleet-tracker",
        "BackendName": "ollama-llama3",    // Rapid generation for live tracking data
        "BackendNames": null,
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null
      },
      {
        "Name": "complex-analytics",
        "Description": "Complex business analytics dashboard with nested metrics, trends, and predictions",
        "Method": "POST",
        "Path": "/data/analytics",
        "Body": "{\"timeRange\":\"last30days\",\"metrics\":[\"revenue\",\"users\",\"churn\"]}",
        "Shape": null,                     // Let LLM determine structure from description
        "IsJsonSchema": false,
        "ApiContextName": "analytics-session",
        "BackendName": "openai-gpt4-turbo", // Use powerful model for complex nested data
        "BackendNames": null,
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null
      },
      {
        "Name": "graphql-query-results",
        "Description": "GraphQL query results with deeply nested user profiles, posts, comments, and relationships",
        "Method": "POST",
        "Path": "/graphql",
        "Body": "{\"query\":\"{ users { id name posts { id title comments { id text author { name } } } } }\"}",
        "Shape": null,
        "IsJsonSchema": false,
        "ApiContextName": null,
        "BackendName": "openai-gpt4-turbo", // Complex relational data needs GPT-4
        "BackendNames": null,
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null
      },
      {
        "Name": "iot-sensors-bulk",
        "Description": "High-volume IoT sensor readings from 1000+ devices",
        "Method": "GET",
        "Path": "/data/sensors",
        "Body": null,
        "Shape": "{\"deviceId\":\"sensor-001\",\"value\":23.5,\"unit\":\"celsius\",\"timestamp\":1234567890}",
        "IsJsonSchema": false,
        "ApiContextName": "iot-network",
        "BackendName": "ollama-llama3",    // Fast local model for simple repetitive data
        "BackendNames": null,              // null = use single BackendName
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null
      },
      {
        "Name": "load-balanced-pool",
        "Description": "Example of load balancing across multiple backends for high throughput",
        "Method": "GET",
        "Path": "/data/load-balanced",
        "Body": null,
        "Shape": "{\"id\":1,\"value\":\"sample data\",\"timestamp\":1234567890}",
        "IsJsonSchema": false,
        "ApiContextName": "high-throughput",
        "BackendName": null,               // null when using BackendNames
        "BackendNames": [                  // Load balance across multiple backends!
          "ollama-llama3",                 // Weight: 3 (gets more requests)
          "ollama-mistral",                // Weight: 2 (gets fewer requests)
          "lmstudio-default"               // Weight: 1 (gets fewest requests)
        ],
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null
      },
      {
        "Name": "massive-dataset-128k",
        "Description": "Massive dataset generation leveraging 128k context window - generates thousands of detailed records with complex nested structures including users, transactions, metadata, and relationships",
        "Method": "GET",
        "Path": "/data/massive",
        "Body": null,
        "Shape": "{\"users\":[{\"id\":1,\"name\":\"John Doe\",\"email\":\"john@example.com\",\"transactions\":[{\"id\":\"tx-001\",\"amount\":99.99,\"timestamp\":1234567890,\"metadata\":{\"category\":\"electronics\",\"tags\":[\"laptop\",\"warranty\"]}}]}]}",
        "IsJsonSchema": false,
        "ApiContextName": "massive-data-context",
        "BackendName": "ollama-mistral-nemo",  // 128k context for huge result sets!
        "BackendNames": null,
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": null,
        "Notes": "Test with MaxItems=10000+ to see Mistral-Nemo handle massive context. Use EnableAutoChunking=true to split into manageable chunks."
      },
      {
        "Name": "error-simulation",
        "Description": "Hub that always returns errors (for testing error handling)",
        "Method": "GET",
        "Path": "/data/errors",
        "Body": null,
        "Shape": null,
        "IsJsonSchema": false,
        "ApiContextName": null,
        "BackendName": null,               // Not applicable for error simulation
        "BackendNames": null,
        "IsActive": false,
        "ConnectionCount": 0,
        "ErrorConfig": {
          "Code": 500,
          "Message": "Internal Server Error",
          "Details": "Database connection failed"
        }
      }
    ],


    // ========================================
    // OPENAPI / SWAGGER SPECIFICATIONS
    // ========================================
    // Load OpenAPI specs to auto-generate mock endpoints.

    "OpenApiSpecs": [
      {
        "Name": "petstore",
        "Source": "https://petstore3.swagger.io/api/v3/openapi.json",
        "BasePath": "/petstore",          // Mount point
        "ContextName": "petstore-demo",   // Shared context for consistency
        "EnableStreaming": false,
        "IncludeTags": null,              // null = all tags
        "ExcludeTags": ["admin"],         // Exclude admin endpoints
        "IncludePaths": null,             // null = all paths
        "ExcludePaths": ["/internal/*"]   // Exclude internal APIs
      },
      {
        "Name": "local-api",
        "Source": "./specs/my-api.yaml",  // Local file path
        "BasePath": "/api/v1",
        "ContextName": null,              // No shared context
        "EnableStreaming": true,          // Add /stream endpoints
        "IncludeTags": ["users", "products"],
        "ExcludeTags": null,
        "IncludePaths": ["/users/*", "/products/*"],
        "ExcludePaths": null
      },
      {
        "Name": "external-api",
        "Source": "https://api.example.com/swagger.json",
        "BasePath": null,                 // Use default from spec
        "ContextName": "external-session",
        "EnableStreaming": false,
        "IncludeTags": null,
        "ExcludeTags": null,
        "IncludePaths": null,
        "ExcludePaths": null
      }
    ],


    // ========================================
    // PLUGGABLE TOOLS & ACTIONS (v2.2.0+)
    // ========================================
    // MCP-compatible tool system for calling HTTP APIs and chaining mock endpoints
    // See: docs/TOOLS_ACTIONS.md

    "ToolExecutionMode": "Disabled",  // Disabled|Explicit|LlmDriven
    "MaxConcurrentTools": 5,
    "MaxToolChainDepth": 3,
    "IncludeToolResultsInResponse": false,

    "Tools": [
      // HTTP Tool - Call external REST API
      {
        "Name": "getUserData",
        "Type": "http",
        "Description": "Fetch user data from JSONPlaceholder API",
        "Enabled": true,
        "TimeoutMs": 10000,
        "EnableCaching": false,
        "HttpConfig": {
          "Endpoint": "https://jsonplaceholder.typicode.com/users/{userId}",
          "Method": "GET",
          "Headers": {
            "Accept": "application/json"
          },
          "ResponsePath": null,           // JSONPath to extract specific fields
          "AuthType": "none",              // none|bearer|basic|apikey
          "AuthToken": null
        },
        "Parameters": {
          "userId": {
            "Type": "string",
            "Description": "User ID to fetch",
            "Required": true
          }
        }
      },

      // HTTP Tool with Authentication
      {
        "Name": "getProtectedData",
        "Type": "http",
        "Description": "Fetch data from protected API endpoint",
        "Enabled": false,
        "TimeoutMs": 15000,
        "EnableCaching": true,
        "HttpConfig": {
          "Endpoint": "https://api.example.com/data/{resourceId}",
          "Method": "GET",
          "Headers": {
            "Accept": "application/json",
            "X-Custom-Header": "{customValue}"
          },
          "AuthType": "bearer",
          "AuthToken": "${API_TOKEN}",    // From environment variable
          "ResponsePath": "$.data"         // Extract only the "data" field
        }
      },

      // HTTP Tool - POST with Body Template
      {
        "Name": "createResource",
        "Type": "http",
        "Description": "Create a new resource via POST",
        "Enabled": true,
        "HttpConfig": {
          "Endpoint": "https://jsonplaceholder.typicode.com/posts",
          "Method": "POST",
          "Headers": {
            "Content-Type": "application/json"
          },
          "BodyTemplate": "{\"title\":\"{title}\",\"body\":\"{body}\",\"userId\":{userId}}",
          "AuthType": "none"
        },
        "Parameters": {
          "title": { "Type": "string", "Required": true },
          "body": { "Type": "string", "Required": true },
          "userId": { "Type": "number", "Required": true }
        }
      },

      // Mock Tool - Call another mock endpoint (decision tree)
      {
        "Name": "getOrderHistory",
        "Type": "mock",
        "Description": "Get user's order history from mock endpoint",
        "Enabled": true,
        "MockConfig": {
          "Endpoint": "/api/mock/users/{userId}/orders",
          "Method": "GET",
          "QueryParams": {
            "limit": "10",
            "status": "completed"
          },
          "Shape": "{\"orders\":[{\"id\":\"string\",\"total\":0.0,\"date\":\"string\"}]}",
          "ContextName": "shopping"
        }
      },

      // Mock Tool - Complex decision tree node
      {
        "Name": "getPremiumFeatures",
        "Type": "mock",
        "Description": "Get premium features if user has premium tier",
        "Enabled": true,
        "MockConfig": {
          "Endpoint": "/api/mock/features/premium",
          "Method": "GET",
          "Shape": "{\"features\":[\"string\"],\"tier\":\"premium\"}",
          "ContextName": null
        }
      }
    ],


    // ========================================
    // PRE-CONFIGURED REST APIs (v2.2.0+)
    // ========================================
    // Define complete API configurations with shape, context, tools, etc.
    // Call by name to apply all settings: /api/configured/{name}
    // List all: GET /api/configured
    // See: docs/REST_API_CONFIGS.md

    "RestApis": [
      // Simple API with shape
      {
        "Name": "users",
        "Description": "Get user list with standardized response shape",
        "Method": "GET",
        "Path": "users",
        "Shape": "{\"users\":[{\"id\":0,\"name\":\"string\",\"email\":\"string\",\"role\":\"string\"}],\"total\":0}",
        "ContextName": null,
        "CustomDescription": "Generate a realistic list of users for a corporate application",
        "CacheCount": 5,
        "Tools": [],
        "DefaultQueryParams": {
          "limit": "10"
        },
        "DefaultHeaders": {},
        "Tags": ["users", "basic"],
        "Enabled": true,
        "UseStreaming": false,
        "RateLimitDelay": null,
        "NCompletions": null,
        "ErrorConfig": null
      },

      // API with OpenAPI spec reference
      {
        "Name": "petstore-pets",
        "Description": "Get pets from Petstore API using OpenAPI schema",
        "Method": "GET",
        "Path": "pets",
        "Shape": null,                     // Will be derived from OpenAPI spec
        "OpenApiSpec": "petstore",         // Reference to loaded OpenAPI spec
        "OpenApiOperationId": "getPets",   // Specific operation from spec
        "ContextName": "petstore-session",
        "CustomDescription": null,
        "CacheCount": 3,
        "Tools": [],
        "DefaultQueryParams": {},
        "DefaultHeaders": {},
        "Tags": ["petstore", "animals"],
        "Enabled": true,
        "UseStreaming": false,
        "RateLimitDelay": null,
        "NCompletions": null,
        "ErrorConfig": null
      },

      // API with shared context and tools
      {
        "Name": "user-profile",
        "Description": "Get enriched user profile with external data",
        "Method": "GET",
        "Path": "profile/{userId}",
        "Shape": "{\"user\":{\"id\":0,\"name\":\"string\",\"email\":\"string\"},\"orders\":[],\"recommendations\":[]}",
        "ContextName": "user-session",
        "CustomDescription": "Combine user data with order history and personalized recommendations",
        "CacheCount": null,
        "Tools": ["getUserData", "getOrderHistory"],  // Execute these tools first
        "DefaultQueryParams": {},
        "DefaultHeaders": {
          "X-API-Version": "v2"
        },
        "Tags": ["users", "composite"],
        "Enabled": true,
        "UseStreaming": false,
        "RateLimitDelay": null,
        "NCompletions": null,
        "ErrorConfig": null
      },

      // API with streaming enabled
      {
        "Name": "live-metrics",
        "Description": "Stream live system metrics",
        "Method": "GET",
        "Path": "metrics/live",
        "Shape": "{\"timestamp\":\"string\",\"cpu\":0.0,\"memory\":0.0,\"requests\":0}",
        "ContextName": "monitoring",
        "CustomDescription": "Real-time system performance metrics",
        "CacheCount": null,
        "Tools": [],
        "DefaultQueryParams": {
          "interval": "5"
        },
        "DefaultHeaders": {},
        "Tags": ["monitoring", "streaming"],
        "Enabled": true,
        "UseStreaming": true,              // Enable SSE streaming
        "RateLimitDelay": null,
        "NCompletions": null,
        "ErrorConfig": null
      },

      // API with rate limiting
      {
        "Name": "rate-limited-api",
        "Description": "API with simulated rate limiting",
        "Method": "GET",
        "Path": "rate-limited/data",
        "Shape": "{\"data\":[],\"timestamp\":\"string\"}",
        "ContextName": null,
        "CustomDescription": null,
        "CacheCount": null,
        "Tools": [],
        "DefaultQueryParams": {},
        "DefaultHeaders": {},
        "Tags": ["testing", "rate-limit"],
        "Enabled": true,
        "UseStreaming": false,
        "RateLimitDelay": "500-2000",      // Simulate 500-2000ms delays
        "NCompletions": null,
        "ErrorConfig": null
      },

      // API with N-completions
      {
        "Name": "variations",
        "Description": "Generate multiple response variations",
        "Method": "GET",
        "Path": "variations/products",
        "Shape": "{\"products\":[{\"id\":0,\"name\":\"string\",\"price\":0.0}]}",
        "ContextName": null,
        "CustomDescription": null,
        "CacheCount": null,
        "Tools": [],
        "DefaultQueryParams": {},
        "DefaultHeaders": {},
        "Tags": ["testing", "batching"],
        "Enabled": true,
        "UseStreaming": false,
        "RateLimitDelay": null,
        "NCompletions": 5,                 // Generate 5 variants
        "ErrorConfig": null
      },

      // API with error simulation
      {
        "Name": "error-test",
        "Description": "Test error handling",
        "Method": "GET",
        "Path": "test/error",
        "Shape": null,
        "ContextName": null,
        "CustomDescription": null,
        "CacheCount": null,
        "Tools": [],
        "DefaultQueryParams": {},
        "DefaultHeaders": {},
        "Tags": ["testing", "errors"],
        "Enabled": true,
        "UseStreaming": false,
        "RateLimitDelay": null,
        "NCompletions": null,
        "ErrorConfig": {
          "Code": 503,
          "Message": "Service temporarily unavailable",
          "Details": "System maintenance in progress"
        }
      },

      // E-commerce complete workflow API
      {
        "Name": "checkout-flow",
        "Description": "Complete e-commerce checkout with multiple steps",
        "Method": "POST",
        "Path": "checkout",
        "Shape": "{\"orderId\":\"string\",\"user\":{},\"items\":[],\"payment\":{},\"shipping\":{},\"total\":0.0}",
        "ContextName": "checkout-session",
        "CustomDescription": "Process complete checkout including user validation, inventory check, and payment",
        "CacheCount": null,
        "Tools": ["getUserData", "getOrderHistory"],
        "DefaultQueryParams": {},
        "DefaultHeaders": {
          "X-Idempotency-Key": "{requestId}"
        },
        "Tags": ["ecommerce", "workflow"],
        "Enabled": true,
        "UseStreaming": false,
        "RateLimitDelay": null,
        "NCompletions": null,
        "ErrorConfig": null
      }
    ],


    // ========================================
    // JOURNEYS - MULTI-STEP USER FLOWS (v2.3.0+)
    // ========================================
    // Define sequences of API calls that simulate realistic user behavior.
    // Each step can have its own shape, context, and prompt hints.
    // LLMs can use management endpoints to select and drive journeys.
    // See: docs/JOURNEYS.md

    "Journeys": {
      "Enabled": true,

      // Default variables available to all journeys (can be overridden per-session)
      "DefaultVariables": {
        "appName": "E-Commerce Demo",
        "apiVersion": "v2"
      },

      // Journey templates
      "Journeys": [
        // REST API User Journey - typical e-commerce flow
        {
          "Name": "ecommerce-browse-purchase",
          "Modality": "Rest",
          "Weight": 3.0,
          "PromptHints": {
            "Scenario": "E-commerce shopping session with realistic user behavior",
            "DataStyle": "Varied product data with realistic prices, descriptions, and inventory",
            "RiskFlavor": "Include payment information, addresses, and session tokens",
            "RandomnessProfile": "medium-variation-but-consistent-ids"
          },
          "Steps": [
            {
              "Method": "GET",
              "Path": "/api/mock/products",
              "ShapeJson": "{\"products\":[{\"id\":0,\"name\":\"string\",\"price\":0.0,\"category\":\"string\"}],\"total\":0}",
              "Description": "Browse product catalog",
              "PromptHints": {
                "HighlightFields": ["name", "price", "category"],
                "Tone": "engaging product descriptions",
                "AdditionalInstructions": "Include a variety of electronics, clothing, and home goods"
              }
            },
            {
              "Method": "GET",
              "Path": "/api/mock/products/{{productId}}",
              "ShapeJson": "{\"id\":0,\"name\":\"string\",\"description\":\"string\",\"price\":0.0,\"inventory\":0,\"reviews\":[]}",
              "Description": "View product details",
              "PromptHints": {
                "ContextKeys": ["lastProductId"],
                "PromoteKeys": ["productId", "name"],
                "LureFields": ["internalSku", "supplierCode"],
                "Tone": "detailed and informative"
              }
            },
            {
              "Method": "POST",
              "Path": "/api/mock/cart",
              "BodyTemplateJson": "{\"productId\":\"{{productId}}\",\"quantity\":1}",
              "ShapeJson": "{\"cartId\":\"string\",\"items\":[],\"subtotal\":0.0}",
              "Description": "Add item to cart",
              "PromptHints": {
                "PromoteKeys": ["productId", "cartId"],
                "Tone": "transactional"
              }
            },
            {
              "Method": "POST",
              "Path": "/api/mock/checkout",
              "BodyTemplateJson": "{\"cartId\":\"{{cartId}}\",\"paymentMethod\":\"card\"}",
              "ShapeJson": "{\"orderId\":\"string\",\"status\":\"string\",\"total\":0.0,\"estimatedDelivery\":\"string\"}",
              "Description": "Complete purchase",
              "PromptHints": {
                "PromoteKeys": ["orderId", "cartId"],
                "LureFields": ["paymentToken", "cardLastFour"],
                "Tone": "confirmation and reassurance"
              }
            }
          ]
        },

        // GraphQL Journey - complex nested queries
        {
          "Name": "graphql-user-exploration",
          "Modality": "GraphQL",
          "Weight": 2.0,
          "PromptHints": {
            "Scenario": "Social platform user exploring profiles and posts",
            "DataStyle": "Rich nested data with relationships between users, posts, and comments",
            "RiskFlavor": "Include email addresses, timestamps, and permission levels"
          },
          "Steps": [
            {
              "Method": "POST",
              "Path": "/graphql",
              "BodyTemplateJson": "{\"query\":\"{ users { id name email } }\"}",
              "Description": "List all users",
              "PromptHints": {
                "HighlightFields": ["id", "name", "email"],
                "Tone": "professional directory listing"
              }
            },
            {
              "Method": "POST",
              "Path": "/graphql",
              "BodyTemplateJson": "{\"query\":\"{ user(id: {{userId}}) { id name posts { id title content createdAt } } }\"}",
              "Description": "View user profile with posts",
              "PromptHints": {
                "ContextKeys": ["userId"],
                "PromoteKeys": ["userId", "name"],
                "Tone": "social media profile"
              }
            },
            {
              "Method": "POST",
              "Path": "/graphql",
              "BodyTemplateJson": "{\"query\":\"{ post(id: {{postId}}) { id title comments { id text author { name } } } }\"}",
              "Description": "View post with comments",
              "PromptHints": {
                "ContextKeys": ["postId"],
                "PromoteKeys": ["postId"],
                "LureFields": ["internalModeration", "reportCount"],
                "Tone": "engaging discussion"
              }
            }
          ]
        },

        // Auth/Security Journey - simulated auth flow
        {
          "Name": "auth-flow-simulation",
          "Modality": "Auth",
          "Weight": 1.0,
          "PromptHints": {
            "Scenario": "Authentication and authorization flow for testing security handling",
            "DataStyle": "Auth tokens, session data, user credentials (synthetic)",
            "RiskFlavor": "Include JWT tokens, refresh tokens, and permissions"
          },
          "Steps": [
            {
              "Method": "POST",
              "Path": "/api/mock/auth/login",
              "BodyTemplateJson": "{\"username\":\"testuser\",\"password\":\"testpass\"}",
              "ShapeJson": "{\"token\":\"string\",\"refreshToken\":\"string\",\"expiresIn\":3600}",
              "Description": "User login",
              "PromptHints": {
                "LureFields": ["internalUserId", "sessionSecret"],
                "Tone": "security-focused"
              }
            },
            {
              "Method": "GET",
              "Path": "/api/mock/auth/me",
              "ShapeJson": "{\"userId\":\"string\",\"username\":\"string\",\"roles\":[],\"permissions\":[]}",
              "Description": "Get current user info",
              "PromptHints": {
                "PromoteKeys": ["userId", "username"],
                "HighlightFields": ["roles", "permissions"],
                "Tone": "identity verification"
              }
            },
            {
              "Method": "POST",
              "Path": "/api/mock/auth/refresh",
              "BodyTemplateJson": "{\"refreshToken\":\"{{refreshToken}}\"}",
              "ShapeJson": "{\"token\":\"string\",\"refreshToken\":\"string\",\"expiresIn\":3600}",
              "Description": "Refresh access token",
              "PromptHints": {
                "ContextKeys": ["refreshToken"],
                "Tone": "token management"
              }
            }
          ]
        },

        // Scanner Journey - API discovery pattern
        {
          "Name": "api-scanner-pattern",
          "Modality": "Scanner",
          "Weight": 0.5,
          "PromptHints": {
            "Scenario": "Automated API scanner discovering endpoints",
            "DataStyle": "API metadata, endpoint listings, version info",
            "RiskFlavor": "Include debug endpoints, version numbers, internal paths"
          },
          "Steps": [
            {
              "Method": "GET",
              "Path": "/api/mock/health",
              "ShapeJson": "{\"status\":\"string\",\"version\":\"string\",\"uptime\":0}",
              "Description": "Health check endpoint",
              "PromptHints": {
                "LureFields": ["buildNumber", "gitCommit", "environment"],
                "Tone": "technical status"
              }
            },
            {
              "Method": "GET",
              "Path": "/api/mock/info",
              "ShapeJson": "{\"name\":\"string\",\"version\":\"string\",\"endpoints\":[]}",
              "Description": "API info endpoint",
              "PromptHints": {
                "HighlightFields": ["endpoints", "version"],
                "LureFields": ["internalEndpoints", "debugMode"],
                "Tone": "API documentation"
              }
            }
          ]
        }
      ]
    }
  }
}
