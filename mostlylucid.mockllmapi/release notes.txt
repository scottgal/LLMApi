mostlylucid.mockllmapi — Release Notes

v1.7.1 — 2025-01-05
- gRPC Demo Page and Bug Fixes
  - Added comprehensive gRPC demo page at /grpc with 4-panel interface
  - Fixed HTTP 415 errors on gRPC binary endpoint
  - Fixed test compatibility (all 196 tests passing)

v1.7.0 — 2025-01-05
- gRPC Service Mocking (MAJOR NEW FEATURE)
  - Upload .proto files to automatically generate gRPC service mocks
  - Dual protocol support: JSON over HTTP and binary Protobuf
  - LLM-powered realistic response generation matching proto schemas
  - Dynamic runtime Protobuf serialization without code generation
  - Management API: POST/GET/DELETE /api/grpc/proto
  - Service endpoints: /api/grpc/{service}/{method} (JSON), /api/grpc/proto/{service}/{method} (binary)
- SSE Streaming Improvements
  - Progressive JSON building with accumulated content in each event
  - Better client experience showing partial JSON structure as it builds

v1.6.1 — 2025-01-05
- Documentation fix: Added missing v1.6.0 release notes

v1.6.0 — 2025-01-04
- Comprehensive Error Simulation
  - Configure realistic error scenarios (rate limits, timeouts, server errors)
  - Per-endpoint error configuration with customizable rates and messages
  - SignalR hub error simulation
- Context Management API Enhancements
  - GET /api/contexts - List all contexts
  - GET /api/contexts/{id} - Get specific context
  - DELETE /api/contexts - Clear all contexts
  - DELETE /api/contexts/{id} - Delete specific context

v1.5.0 — 2025-01-03
- API Contexts for multi-step workflows with shared memory across requests
- Native GraphQL support with automatic schema-based response generation
- Fully modular architecture - use only the protocols you need
- Polly resilience policies with exponential backoff and circuit breaker
- OpenAPI specification support with automatic endpoint generation

v1.4.0 — 2024-12-30
- SignalR real-time mock data streaming
- Hub context management with automatic cleanup
- Advanced shape extraction from query/header/body
- Custom prompt template support

v1.3.0 — 2024-12-27
- Server-Sent Events (SSE) streaming support
- Token-by-token response streaming
- Configurable streaming endpoints

v1.2.0 — 2024-12-25
- Multi-target framework support (.NET 8.0 and .NET 9.0)
- Improved error handling and logging
- Performance optimizations

v1.1.0 — 2024-12-20
- Custom prompt templates
- Temperature and timeout configuration
- Enhanced documentation

v1.0.0 — 2024-12-15
- Initial release
- LLM-powered mock API responses via Ollama
- Flexible shape-based response generation
- Easy ASP.NET Core integration
