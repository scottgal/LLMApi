mostlylucid.mockllmapi — Release Notes

Changelog is sourced from git tags (v.*). Newest first. Each entry reflects the actual changes in the repository (files, metadata, docs) for that tag.

v1.2.0 — 2025-11-04
- Native GraphQL support and fully modular protocol architecture.
  - Added: GraphQL API Support
    - Native GraphQL endpoint: POST to /api/mock/graphql with standard GraphQL queries
    - Query-driven data generation (query itself defines response structure)
    - Full GraphQL request support: variables, operation names, nested fields
    - Proper GraphQL response format: { "data": {...} } or { "data": null, "errors": [...] }
    - Intelligent LLM integration for contextually appropriate mock data
  - Added: Fully Modular Architecture (MAJOR)
    - Complete protocol independence: Each protocol (REST, Streaming, GraphQL, SignalR) can be added/mapped independently
    - New modular Add methods: AddLLMockRest(), AddLLMockStreaming(), AddLLMockGraphQL(), AddLLMockSignalR()
    - New modular Map methods: MapLLMockRest(), MapLLMockStreaming(), MapLLMockGraphQL(), MapLLMockSignalR()
    - Smart service registration prevents duplicates when multiple Add methods are called
    - Benefits: 30-40% reduced memory footprint, faster startup, clearer code intent, mix-and-match protocols
    - Full backward compatibility: AddLLMockApi() and MapLLMockApi() still work exactly as before
  - Added: Backward Compatibility for Method Names
    - Deprecated method aliases: Addmostlylucid_mockllmapi() and Mapmostlylucid_mockllmapi()
    - [Obsolete] attributes guide users to new method names (AddLLMockApi/MapLLMockApi)
    - No breaking changes - all existing code continues to work
  - Added: Shared JSON Extraction Utility
    - Created JsonExtractor.cs to eliminate code duplication
    - Handles markdown code blocks in LLM responses
    - Validates JSON structure and extracts clean JSON from mixed content
  - Changed: mostlylucid.mockllmapi/RequestHandlers/GraphQLRequestHandler.cs (NEW)
    - Dedicated handler for GraphQL requests
    - Parses GraphQL queries and extracts structure for LLM context
    - Supports variables, operation names, nested fields
  - Changed: mostlylucid.mockllmapi/Services/JsonExtractor.cs (NEW)
    - Shared utility for extracting JSON from LLM responses
    - Used by both RegularRequestHandler and GraphQLRequestHandler
  - Changed: mostlylucid.mockllmapi/LLMockApiExtensions.cs
    - Major refactoring for modular architecture
    - Separated registration into Core, REST, Streaming, GraphQL, and SignalR services
    - Added backward compatibility aliases with [Obsolete] attributes
    - Organized code with #region directives for clarity
  - Changed: mostlylucid.mockllmapi/RequestHandlers/RegularRequestHandler.cs
    - Updated to use shared JsonExtractor utility
  - Changed: README.md
    - Added comprehensive GraphQL section with examples
    - Documented modular architecture with usage patterns
  - Changed: LLMApi/LLMApi.http
    - Added 5 GraphQL test examples (simple user query, variables, nested fields, e-commerce, organizational data)
  - Added: MODULAR_EXAMPLES.md (NEW)
    - Comprehensive examples for all modular usage patterns
    - REST only, GraphQL only, Streaming only, SignalR only examples
    - Mix-and-match examples
    - Migration guide from v1.1.0 to v1.2.0
  - Changed: RELEASE_NOTES.md
    - Updated with v1.2.0 feature documentation
  - Outcome:
    - GraphQL support for frontend developers and API prototyping
    - Fully modular architecture for reduced overhead and clearer intent
    - No breaking changes - complete backward compatibility
    - Better code organization and reduced duplication

v1.1.0 — 2025-11-03
- Major SignalR enhancements: Full context lifecycle management, interactive demo UI improvements, enhanced data display, and simplified configuration.
  - Added: SignalR Context Lifecycle Management
    - New endpoints: POST /api/mock/contexts/{name}/start and /stop for runtime control
    - Contexts can now be started/stopped dynamically without deletion
    - Active/inactive status tracking with visual indicators in UI
  - Added: Connection Tracking
    - Real-time connection count per context
    - Automatic increment/decrement on subscribe/unsubscribe
    - Displayed in context management panel
  - Added: Interactive Management UI (Index.cshtml - SignalR Demo)
    - New 3-column layout with "Active Contexts" panel
    - Live context list with status badges (Active/Stopped)
    - Per-context controls: Connect, Disconnect, Start, Stop, Delete
    - Auto-refresh on context creation/modification
    - Quick-start example buttons for 5 pre-configured scenarios:
      * IoT Sensors
      * Stock Market
      * E-commerce Orders
      * Server Metrics
      * Gaming Leaderboard
  - Added: JSON Syntax Highlighting
    - Dark-themed code display with color-coded JSON elements
    - Keys (red), strings (green), numbers (orange), booleans (cyan), null (purple)
    - No external dependencies - lightweight built-in highlighter
    - Clean, readable display of streaming data
  - Added: Automatic appsettings Context Registration
    - Contexts configured in appsettings.json now automatically appear in Active Contexts panel
    - Seamless integration between static configuration and dynamic management
    - Full lifecycle control (start/stop/delete) for all context types
  - Added: Simplified SignalR Configuration
    - Context creation now requires only Name and Description (HTTP Method/Path no longer exposed to users)
    - Method/Path/Body fields are now internal - used only for LLM prompt context
    - Clearer separation: SignalR uses WebSockets, not HTTP
    - More intuitive configuration focused on what data to generate, not how
  - Added: SSE Demo Quick-Start Buttons (Streaming.cshtml)
    - 4 one-click streaming examples:
      * User List
      * Product Catalog
      * Order Details
      * Weather Data
    - Auto-populate form and start streaming
  - Added: Smart Adaptive Response Caching for SignalR Contexts
    - Instant first messages: Cache pre-filled on startup for all active contexts
    - Adaptive batch sizing: Measures first response generation time, calculates optimal batch size (pushInterval / generationTime)
    - Per-context cache queues to store pre-generated responses
    - Background refilling: Auto-refills when cache drops below 50%
    - Intelligent batching: Generates exactly enough responses to fill the time until next push
    - Significantly reduces LLM load and improves response consistency
    - Example: If generation takes 500ms and push interval is 5000ms, system automatically batches 10 responses
  - Changed: mostlylucid.mockllmapi/Models/HubContextConfig.cs
    - Added IsActive property (default: true) for start/stop functionality
    - Added ConnectionCount property for tracking connected clients
  - Changed: mostlylucid.mockllmapi/Services/DynamicHubContextManager.cs
    - New methods: StartContext, StopContext, IncrementConnectionCount, DecrementConnectionCount
    - Thread-safe connection tracking
  - Changed: mostlylucid.mockllmapi/Hubs/MockLlmHub.cs
    - Integration with DynamicHubContextManager for connection tracking
    - Subscribe/Unsubscribe now update connection counts
  - Changed: mostlylucid.mockllmapi/Services/MockDataBackgroundService.cs
    - Only generates data for active contexts
    - Registers appsettings contexts with DynamicHubContextManager on startup
    - Unified context processing (static and dynamic contexts treated equally)
    - Smart adaptive batching: Measures generation time, calculates optimal batch size per context
    - Pre-fills all active context caches on startup for instant first messages
    - Per-context cache queues with intelligent prefilling and refilling
    - Added comprehensive logging for context processing and batch sizing
    - Shows configured contexts and calculated batch sizes on startup
  - Changed: LLMApi/Pages/Index.cshtml
    - Fixed Unix timestamp (milliseconds) handling for proper time display
    - Display shows only JSON data (extracts message.data field)
    - Added syntaxHighlight() function for color-coded JSON
    - Improved error handling for missing/invalid message fields
  - Changed: mostlylucid.mockllmapi/LLMockApiExtensions.cs
    - Fixed duplicate context registration bug (was binding config twice)
    - AddLLMockSignalR no longer re-configures options
    - Support for both JSON and form-encoded context creation
    - New management endpoints for start/stop operations
  - Changed: mostlylucid.mockllmapi/LLMockApiOptions.cs
    - Removed default "default" context to prevent duplication issues
  - Outcome:
    - Complete lifecycle management of SignalR contexts
    - Better visibility into active connections and data generation
    - Improved developer experience with interactive UI and beautiful data display
    - Faster prototyping with quick-start examples
    - More reliable context management with proper state tracking
    - Reduced LLM load with intelligent caching
    - Seamless integration of static and dynamic contexts

v1.0.6 — 2025-11-02
- Add response caching and response-schema header; expand samples and tests.
  - Changed: mostlylucid.mockllmapi/LLMockApiService.cs
    - Implement service-level response caching via $cache in shape; primes N variants per key and refills in background.
    - Added optional X-Response-Schema header with shape echo (bounded length) controlled by IncludeShapeInResponse or ?includeSchema=true.
  - Changed: mostlylucid.mockllmapi/LLMockApiOptions.cs
    - New options: IncludeShapeInResponse, MaxCachePerKey.
  - Changed: mostlylucid.mockllmapi/LLMockApiExtensions.cs
    - Non-streaming endpoints now use caching when $cache is provided; add schema header when enabled.
  - Changed: LLMApi/LLMApi.http
    - Added sections for shape control, streaming endpoints, and caching examples.
  - Changed: LLMApi.Tests/LLMockApiServiceTests.cs
    - Added tests for cache priming/depletion/refill and shape sanitization.
  - Changed: README.md
    - Document new features and usage.
  - Outcome: Faster repeat calls with controlled variability and optional visibility of the generation schema.

v1.0.5 — 2025-11-02
- Add package icon to NuGet package metadata.
  - Changed: mostlylucid.mockllmapi/mostlylucid.mockllmapi.csproj
    - Declared <PackageIcon> icon.png
    - Ensured icon.png is packed into the .nupkg
  - Outcome: The package now displays a proper icon on NuGet.org and in IDE package managers.

v1.0.4 — 2025-11-02
- Fix package RepositoryUrl metadata (NuGet link) in project file.
  - Changed: mostlylucid.mockllmapi/mostlylucid.mockllmapi.csproj
    - RepositoryUrl updated to https://github.com/scottgal/LLMApi

v1.0.2 — 2025-11-02
- Fix NuGet badge links in README for correct package name.
  - Changed: README.md
    - Updated badge image and target URLs to match the actual package ID.

v1.0.1 — 2025-11-02
- Add NuGet badges to README and tidy sample code formatting.
  - Changed: README.md
    - Added shields.io NuGet badges (version and downloads)
  - Changed: LLMApi/Program.cs
    - Minor formatting/cleanup

v0.0.3 — 2025-11-02
- Enhance NuGet publishing workflow with OIDC login and improve setup docs.
  - Changed: .github/workflows/publish-nuget.yml
    - Adjusted workflow to support OIDC-based authentication
  - Changed: .github/NUGET_SETUP.md
    - Updated instructions to reflect the improved workflow
  - Changed: CLAUDE.md
    - Documentation grooming

v0.0.2 — 2025-11-02
- Adopt Unlicense and refine NuGet publishing steps and workflow.
  - Added: LICENSE (Unlicense)
  - Changed: .github/workflows/publish-nuget.yml
  - Changed: .github/NUGET_SETUP.md

v0.0.1 — 2025-11-02
- Switch license to Unlicense and update docs for GitHub Actions–based automated NuGet publishing.
  - Summary commit: Switch license to Unlicense and update documentation for GitHub Actions-based automated NuGet publishing.

Notes
- Package versioning is driven by git tags (v.*): the NuGet release notes and this file reflect those tags.
- See README.md for usage, configuration, and examples.
